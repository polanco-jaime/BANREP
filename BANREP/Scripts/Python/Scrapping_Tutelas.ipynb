{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaN3YrcL/mz6GHtroQTM4m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JAPJ182/BANREP/blob/main/BANREP/Scripts/Python/Scrapping_Tutelas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1. Active all libraries incluid the function for scrapping tutelas in Colombia"
      ],
      "metadata": {
        "id": "IzYw98eM8lZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install html-table-parser-python3\n",
        "url =  \"https://raw.githubusercontent.com/JAPJ182/BANREP/main/Scripts/scrapping_tutelas.py\"\n",
        "!wget --no-cache --backups=1 {url}\n",
        "\n",
        "exec(compile(open(\"scrapping_tutelas.py\", \"rb\").read(), \"scrapping_tutelas.py\", 'exec'))\n",
        "import urllib.request\n",
        "from pprint import pprint\n",
        "from html_table_parser.parser import HTMLTableParser\n",
        "import pandas as pd\n",
        "import requests\n",
        "import lxml.html as lh\n",
        "import time\n",
        "!rm scrapping_tutelas.py\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "folder_drive = \"/content/drive/MyDrive/Tutelas EPS/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HH0vR4C3iV0",
        "outputId": "ba81debe-680d-477c-a51b-bce26da2b43f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting html-table-parser-python3\n",
            "  Downloading html_table_parser_python3-0.3.1-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: html-table-parser-python3\n",
            "Successfully installed html-table-parser-python3-0.3.1\n",
            "--2022-12-21 15:39:19--  https://raw.githubusercontent.com/JAPJ182/BANREP/main/Scripts/scrapping_tutelas.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2021 (2.0K) [text/plain]\n",
            "Failed to rename scrapping_tutelas.py to scrapping_tutelas.py.1: (2) No such file or directory\n",
            "Saving to: ‘scrapping_tutelas.py’\n",
            "\n",
            "scrapping_tutelas.p 100%[===================>]   1.97K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-21 15:39:20 (37.3 MB/s) - ‘scrapping_tutelas.py’ saved [2021/2021]\n",
            "\n",
            "Mounted at drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2. A loop is created to extract each possible Guardianship defendant agreement for each month, EPS and year."
      ],
      "metadata": {
        "id": "MfutyXr18zXW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anio = [ '2000' , '2001' , '2002' , '2003' , '2004' , '2005' , \n",
        "        '2006' , '2007' , '2008' , '2009' , '2010' , '2011' ,\n",
        "        '2012' , '2013' , '2014' , '2015' , '2016' , '2017' ,\n",
        "        '2018' , '2019' , '2020' , '2021', '2022' ]\n",
        "mes = ['01' , '02' , '03'  , '04'  , '05'  , '06' , '07'  , '08', '09' , '10' , '11' , '12' ]\n",
        "keyword = [\n",
        "   'eps', 'e.p.s' ,\t\n",
        "   'CAJA DE COMPENSACION FAMILIAR DEL HUILA', 'COMFAMILIAR HUILA',\n",
        "     'CAMACOL'  , 'COMFAMA' , 'COMFAMILIAR CARTAGENA' , 'COMFABOY' , 'COLSUBSIDIO' ,\t'FAMISANAR' ,\t'CAFAM' ,\n",
        "    'COMFACOR' ,\t'CAJA DE COMPENSACION FAMILIAR DE CORDOBA' ,\t 'COMFAGUAJIRA' ,\t'CAJA DE COMPENSACION FAMILIAR DE LA GUAJIRA' ,\t'COMFAMILIAR GUAJIRA' ,\n",
        "       'COMFAMILIAR NARIÑO' ,\t'CAJA DE COMPENSACION FAMILIAR DE NARIÑO' ,\t\n",
        "     'COMFAMILIAR NARIÑO' ,\t'COMFENALCO QUINDIO' ,\t'CAJA DE COMPENSACION FAMILIAR DE FENALCO' , 'COMFAMILIAR RISARALDA' ,\t\t\n",
        "     'CAJASAN' ,\t'CAJA SANTANDEREANA DE SUBSIDIO FAMILIAR' ,\t'COMFENALCO SANTANDER' , 'COMFASUCRE' , 'CAFABA' ,\t'CAJA DE COMPENSACION FAMILIAR DE BARRANCABERMEJA' ,\t\n",
        "     'COMFENALCO TOLIMA' ,\t\t'COMFACARTAGO' ,\t\t'COMFANORTE' ,\t'CAJA DE COMPENSACION FAMILIAR DEL NORTE DE SANTANDER' ,\t\n",
        "     'COMFAORIENTE' ,\t'CAJA DE COMPENSACION FAMILIAR CCF DEL ORIENTE COLOMBIANO ' ,\t'COMFACUNDI' ,\t'CAJA DE COMPENSACION FAMILIAR DE CUNDINAMARCA' ,\t\n",
        "     'COMFENALCO CUNDINAMARCA' ,\t\t'CAJACOPI ATLANTICO' , 'COMFACHOCO' , 'COMFACA' , 'EMPRESAS PUBLICAS DE MEDELLIN-DEPARTAMENTO MEDICO' ,\t\t\n",
        "      'FERROCARRILES' ,\t\t'ALIANSALUD ' ,\n",
        "       'SALUD TOTAL ' , 'CAFESALUD' , 'SANITAS' ,\t\t'SEGUROS SOCIALES ' , 'COMPENSAR' ,\t\t\n",
        "      'COMFENALCO ANTIOQUIA' ,\t\t'SURAMERICANA' , 'COMFENALCO VALLE' ,\n",
        "         'SALUDCOOP' ,\t\t'HUMANA VIVIR' , 'COLPATRIA' ,\t\t\n",
        "      'COOMEVA' ,\t\t'SERVICIO OCCIDENTAL DE SALUD' , 'CAPRECOM' , 'CONVIDA' ,\n",
        "      'CRUZ BLANCA' , 'CAPRESOCA' ,\t\t\n",
        "      'SOLSALUD' ,\t\t'CALISALUD' , 'CONDOR  SA' , 'SELVASALUD' , 'SALUDVIDA' , 'SALUDCOLOMBIA' , 'SALUD ATENCION HUMANA' ,\t\t\n",
        "      'NUEVA EPS' ,\t\t'MULTIMEDICAS SALUD' , 'GOLDEN GROUP' , 'COOSALUD' ,\n",
        "       'MEDIMAS' , 'SALUD MIA' , 'MUTUAL SER' ,\t\t\n",
        "       'DUSAKAWI' ,\t\t'MANEXKA' , 'ASOCIACION INDIGENA DEL CAUCA' , 'ANASWAYUU' , 'MALLAMAS' , 'PIJAOS SALUD' ,\t\t\n",
        "       'CAPITAL SALUD' ,\t\t'SAVIA SALUD' , 'EMDISALUD ' ,\n",
        "       'COOSALUD' , 'ASMET  SALUD' ,\t'ASMET  ' , 'ASTREA' ,\t\t\n",
        "      'AMBUQ' ,\t'ASOCIACION MUTUAL BARRIOS UNIDOS DE QUIBDO' ,\n",
        "      \t'ECOOPSOS' ,\t'ENTIDAD COOPERATIVA SOLDE SALUD DEL NORTE DE SOACHA' ,\t\n",
        "      'MALLAMAS' ,\t'ASOCIACION MUTUAL' ,\t'EMSSANAR' ,\t'ASOCIACION MUTUAL EMPRESA SOLIDARIA DE SALUD DE NARIÑO ' ,\t\n",
        "      'COMPARTA' ,\t'COOPERATIVA DE SALUD COMUNITARIA' , 'ASOCIACION MUTUAL SER EMPRESA SOLIDARIA DE SALUD' ,\t\t\n",
        "      'FUERZAS MILITARES' ,\t\t'POLICIA NACIONAL' , 'ECOPETROL' , 'MAGISTERIO' ,\t\t\n",
        "      'UATLANTICO' ,\t\t'INPEC'  , 'CAJASALUD' ,\t\t\n",
        "      'COMFAMILIARES EN SALUD UT' , 'CONVENIO COMFENALCO UT' , 'CONVENIO CAMACOL CONFAMA UT' ,\n",
        "      'empresa prestadora de salud'\n",
        "\n",
        "]\n",
        "\n",
        "# \n",
        "for i in keyword:\n",
        "  # primero: descarga todos lso registros, segun la palabra clave\n",
        "  time.sleep(5)\n",
        "\n",
        "  try:\n",
        "    appended_data = []\n",
        "    temp = scrap_tutelas( keyword = i )\n",
        "  except IndexError as e:\n",
        "    print(f\"{e}\")\n",
        "  except UnicodeEncodeError as U:\n",
        "    print(f\"{U}\")\n",
        "  #si esta priemra descarga tiene menos de 5500 registros entonces de inmediato se imprime el csv del archivo. \n",
        "  if temp.shape[0] <= 5500:\n",
        "    print('se corre la eps {}'.format(i))\n",
        "    temp['keyword'] = i\n",
        "    temp.to_parquet(folder_drive+i+'.parquet',index=False  )\n",
        "    # si existen mas de 5500 registros entonces descargamos por cada año, en este casod esde el 2000 al 2022\n",
        "  else:\n",
        "    for j in anio:\n",
        "      # \n",
        "        try:\n",
        "          \n",
        "          temp = scrap_tutelas( keyword = i, anio = j) \n",
        "          if temp.shape[0] >= 5500:\n",
        "    #Ahora bien si al descargar por año tambien tiene mas de 5500 entonces se descarga por ems\n",
        "            for k in mes:\n",
        "              print('se corre la eps {}, del año {}, y el mes {} '.format(i,j, k )) #,k \n",
        "              temp = scrap_tutelas( keyword = i , anio = j, mes= k ) # \n",
        "              appended_data.append(temp)\n",
        "          else:\n",
        "            print('se corre la eps {}, del año {} '.format(i,j)) #,k , y el mes {}\n",
        "            appended_data.append(temp)\n",
        "\n",
        "          df = pd.concat(appended_data)\n",
        "          df['keyword'] = i\n",
        "          df.to_parquet(folder_drive+i+'.parquet', index=False )\n",
        "\n",
        "        except IndexError as e:\n",
        "          print(f\"{e}\")\n",
        "          pass\n",
        "\n"
      ],
      "metadata": {
        "id": "QwTzzmLk63Df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339776b9-0a46-49db-d548-b35f767acae1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "se corre la eps empresa prestadora de salud\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d_O33T1lUNmY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}